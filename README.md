# SI671 Assingment 1

**Task**: Build a reccomender system that predicts a rating on a scale from 1 to 5 for a given user and product. We are provided with a training set of ~1.3 million reviews in JSON format with which to make 170k predictions. 

## Precomputing
The first, and the longest step, is the precomputing and storing of data in files. The json files containing the reviews are iterated through and sorted, providing two reference indexes – one for users and one for movies. These are used to match the reviewerID/asin of a given user/movie with its row/column in the user-item matrix. The user-item matrix is then created using scipy’s linked list sparse matrix, which allows for coordinate access to the matrix while still maintaining a small file-size footprint. This is by far the longest step in the process, and so the resulting matrix is saved to a .npz file that can be loaded straight from disk in the future. After the user-item matrix is complete, the singular value decomposition can be performed, the resulting right singular matrix of which is also stored to disk as the “movie to concept” matrix from which we can determine movie similarities. Finally, the user-item matrix is scanned row-wise and column-wise, with the averages of all non-zero values stored in the user and movie indexes as baseline estimates. 

## Prediction
Given a User and a Movie, the PredictReview function first checks to see if this is going to be a cold start problem – if either the user or the movie (or both) doesn’t appear in the user-item matrix, we need to use the baselines alone to come up with a prediction. If the user is missing, then the movie’s baseline average is added to the overall average rating. If the movie is missing, then the user’s baseline average is added to the overall. If both, the overall is all we have to work with. 
Assuming we have both a user and a movie with data, we look at all of the other movies this user has rated and compare them via the cosine similarity of their columns in the movie to concept matrix. The higher the similarity of two movies, the more likely we are to assume that the user will review this movie in a similar way. We take the ratings of all similar movies rated by this user, offset them by the movie’s overall baseline average, weight them according to their similarity, and calculate the weighted average. In the event we don’t have enough movies considered similar, we drop the threshold for similarity to our specified minimum and calculate the weighted average of those movies instead. The overall weighted average is then added to the user and movie baseline to come up with a prediction. As a final step we set a floor of 1 and a ceiling of 5, as our predictions are capable of going outside of those ranges and those are the limits for a review in the data set. 

## Parameters

| Parameter|Description|
|:------------- |-------------|
| K: the K value for the SVD Matrix      | Very small values (5-10) result in poor accuracy scores, Large values (1000+) take increasingly long to calculate, and don’t seem to add much in accuracy beyond 100. I ended up with k=2000, as that was the largest I calculated and it didn’t have an effect on prediction times nor did it hurt accuracy.  |
| min_sim: the minimum level of similarity in order to consider two movies similar enough to consider| If this is set too low, we’re including ratings for movies that are not particularly similar. Too high and we won’t have enough ratings to draw a reasonable guess from. The best value seems to fall around 0.75.      |
| baseline_weighting: how much to increase or decrease the effect of the baseline averages on the final prediction | I noticed that often the addition of the baselines was making bad predictions even worse. This value scales the effect of the baselines on the final estimate. The best value seems to fall around 0.75.     |
| desired_sim_records | The minimum number of similar records we try to reach before calculating a prediction. If there are more movies that are available that are perhaps not as similar as we have set in the minimum similarity, we will consider those as well up to the limit set here. Either two or three seems to get the best results.|
| backup_min_sim | The absolute minimum similarity we will consider in order to calculate a prediction. Anything below 0.5 starts to create too much unpredictability. (Must be less than min_sim.)|
